[
    {
      "question": "What foundational shift in AI necessitated the evolution of prompt engineering into the formal discipline of Context Engineering?",
      "answer": "The necessity arose because Large Language Models (LLMs) have evolved from simple instruction-following systems into the **core reasoning engines of complex applications** [1]. This shift demanded more sophisticated methods for designing and managing their informational payloads, leading to the formal discipline of Context Engineering [1, 2]. (Source: 1 Introduction, 3 Why Context Engineering)"
    },
    {
      "question": "How does the target optimization complexity, denoted as $F^*$, differ fundamentally between traditional prompt engineering and Context Engineering?",
      "answer": "For traditional prompt engineering, the complexity involves a manual or automated search over a simple string space, where the target is maximizing output probability given a static string prompt ($\\arg \\max_{prompt} P_{\\theta}(Y|prompt)$) [3]. Context Engineering, however, involves **system-level optimization** of $F^* = \\arg \\max_F E_{\\tau\\sim T} [Reward(P_{\\theta}(Y|C_F (\\tau)), Y^*_{\\tau})]$, where F represents a set of complex context functions like Assembly, Retrieval, and Selection [3]. (Source: 3.1 Definition of Context Engineering)"
    }
  ]